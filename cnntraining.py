# -*- coding: utf-8 -*-
"""CNNTraining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFBHG6ZvmuHJrQMXVzzV970mbOJSE2jr
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from google.colab import drive
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

drive.mount('/content/drive')

X = np.load('./drive/MyDrive/AIM Hackathon/data/train/X.npy')
Y = np.genfromtxt('train.csv', delimiter=',')

print('Shape of training data: ',X.shape)
X = tf.expand_dims(X,-1)
print('New Shape of training data: ',X.shape)

X_train = X[:9000]
Y_train = Y[:9000]
X_validation = X[9000:]
Y_validation = Y[9000:]

BUFFER_SIZE = 60000
BATCH_SIZE = 256

scaler = StandardScaler()
print(scaler.fit(Y_train))
Y_train = scaler.transform(Y_train)
Y_validation = scaler.transform(Y_validation)

def r2_score_t(y_true, y_pred):
  y,y_hat = tf.squeeze(y_true),tf.squeeze(y_pred)
  y_bar = tf.reduce_mean(y)
  r2 = 1 - tf.reduce_sum(tf.square(y-y_hat))/tf.reduce_sum(tf.square(y-y_bar))
  return r2

initialModel = models.Sequential()

initialModel.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(40, 120, 1)))
print(initialModel.output_shape)
initialModel.add(layers.MaxPooling2D((2, 2)))
print(initialModel.output_shape)
initialModel.add(layers.Conv2D(64, (2, 2), activation='relu'))
print(initialModel.output_shape)
initialModel.add(layers.MaxPooling2D((2, 2)))
print(initialModel.output_shape)
initialModel.add(layers.Conv2D(128, (2, 2), activation='relu'))
print(initialModel.output_shape)
initialModel.add(layers.MaxPooling2D((2, 2)))
print(initialModel.output_shape)
initialModel.add(layers.Conv2D(256, (1, 1), activation='relu'))
print(initialModel.output_shape)
initialModel.add(layers.MaxPooling2D((2, 2)))


initialModel.add(layers.Flatten())
initialModel.add(layers.Dense(256, activation='relu'))
initialModel.add(layers.Dense(6, activation='LeakyReLU'))
initialModel.summary()


initialModel.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError(),r2_score_t])

history = initialModel.fit(X_train, Y_train, epochs=30, batch_size = 32,validation_data=(X_validation, Y_validation))

plt.plot(history.history['mean_absolute_error'], label='Train MAE')
plt.plot(history.history['val_mean_absolute_error'], label='Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend(loc='upper right')

train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

initialModel.trainable = False;

def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(15*5*64, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((5, 15, 64)))
    assert model.output_shape == (None, 5, 15, 64)  # Note: None is the batch size

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    print(model.output_shape)
    assert model.output_shape == (None, 5, 15, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    print(model.output_shape)
    assert model.output_shape == (None, 10, 30, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    print(model.output_shape)
    assert model.output_shape == (None, 20, 60, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='sigmoid'))
    assert model.output_shape == (None, 40, 120, 1)
    print(model.summary())

    return model

generator = make_generator_model()

noise = tf.random.normal([1, 100])
generated_image = generator(noise, training=False)

plt.imshow(generated_image[0, :, :, 0], cmap='gray', vmin=0, vmax=1)

def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(32, (5, 5), strides=(1, 1), padding='same', input_shape=[40, 120, 1]))

    #print(model.output_shape)
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same'))
    #print(model.output_shape)
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))
    #print(model.output_shape)
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    #print(model.output_shape)
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())
    model.add(layers.Dense(1))
    print(model.summary())
    return model

discriminator = make_discriminator_model()
decision = discriminator(generated_image)
print(decision)

# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

def tf_inv_scale(y_scaled):
      scale=tf.cast(tf.convert_to_tensor(scaler.scale_), "float32")
      mean=tf.cast(tf.convert_to_tensor(scaler.mean_), "float32")
      return tf.cast(y_scaled*scale+mean, "float32")

def generator_aux_loss(generated_images):
    prediction = initialModel(generated_images)
    invPred = tf_inv_scale(prediction)

    return tf.reduce_sum(invPred)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

EPOCHS = 70
noise_dim = 100
num_examples_to_generate = 16

# You will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# Notice the use of `tf.function`
# This annotation causes the function to be "compiled".
theta = 0.000001
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)

      gen_aux_loss = generator_aux_loss(generated_images)
      tot_gen_loss = gen_loss+gen_aux_loss*theta

      disc_loss = discriminator_loss(real_output, fake_output)

    #gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_generator = gen_tape.gradient(tot_gen_loss, generator.trainable_variables)

    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    #generator_optimizer.apply_gradients(zip(gradients_of_generator_2, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  import time
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)




    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))
    generate_and_save_images(generator,
                           epochs,
                           seed)

  # Generate after the final epoch

def generate_and_save_images(model, epoch, test_input):
  # Notice `training` is set to False.
  # This is so all layers run in inference mode (batchnorm).
  predictions = model(test_input, training=False)

  fig = plt.figure(figsize=(4, 4))

  for i in range(predictions.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(predictions[i, :, :, 0] * 255, cmap='gray')
      plt.axis('off')

  plt.savefig('image_at_epoch_' + str(epoch) + '.png')
  plt.show()

train(train_dataset, EPOCHS)